{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Attacks\n",
    "- This notebook serves to demonstrate the vulnerablity of our BERT-BILSTM model to adversarial examples\n",
    "- To perform our attack, we made use of the TextAttack library: https://github.com/QData/TextAttack\n",
    "- This library hosts a number of attack implementation on NLP DNNs\n",
    "- To demonstrate adversarial attacks, we utilised the A2T-MLM attack: https://arxiv.org/pdf/2109.00544.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, PreTrainedModel, PretrainedConfig\n",
    "\n",
    "import textattack\n",
    "from textattack.models.wrappers import HuggingFaceModelWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define seed for reproducability\n",
    "def set_seed(seed = 0): \n",
    "    '''\n",
    "    set random seed\n",
    "    '''\n",
    "    # random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"IMDB Dataset.csv\") # read csv\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.3, shuffle=True) # train test split of 7:3 ratio\n",
    "\n",
    "# maps str to int\n",
    "polarity_class = {\"negative\":0, \"positive\":1} # binary classes\n",
    "y_train = y_train.apply(lambda x: polarity_class[x]) \n",
    "y_test = y_test.apply(lambda x: polarity_class[x])\n",
    "\n",
    "# get adversarial examples dataset, we only take a sample of original test set for computational purposes\n",
    "adv_X_train, adv_X_test, adv_y_train, adv_y_test = train_test_split(X_test, y_test, test_size=1/6, shuffle=True) \n",
    "\n",
    "adv_y_train = adv_y_train.values\n",
    "adv_y_test = adv_y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# truncate texts, adversarial examples are slightly computationally\n",
    "temp_text_truncated = []\n",
    "for idx, review in enumerate(adv_X_test): \n",
    "    split_rev = review.split(\" \")[:150] \n",
    "    concat_rev = ' '.join(split_rev) \n",
    "    temp_text_truncated.append((concat_rev, int(adv_y_test[idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap model to be compatible with TextAttack library\n",
    "class MyConfig(PretrainedConfig):\n",
    "    model_type = 'mymodel'\n",
    "    def __init__(self, important_param=42, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.important_param = important_param\n",
    "\n",
    "# Bert Model   \n",
    "class BERT_Bi_Arch(PreTrainedModel): # for binary class\n",
    "    config_class = MyConfig\n",
    "    \n",
    "    def __init__(self, config):\n",
    "        super(BERT_Bi_Arch, self).__init__(config)\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.softmax = nn.LogSoftmax(dim=1) \n",
    "        self.lstm = nn.LSTM(768, 256, batch_first=True,bidirectional=True)\n",
    "        self.linear = nn.Linear(256*2, 2)\n",
    "        self.logits = 0       \n",
    "        self.loss_function = nn.NLLLoss() # loss function\n",
    "        \n",
    "    def __loss__(self, labels): # get loss\n",
    "        loss = self.loss_function(self.logits, labels)\n",
    "        return loss\n",
    "    \n",
    "    def get_input_embeddings(self):\n",
    "        return self.bert.get_input_embeddings() \n",
    "\n",
    "    def __call__(self, input_ids, attention_mask, token_type_ids):\n",
    "        sequence_output, pooled_output = self.bert(input_ids, attention_mask=attention_mask, return_dict=False)\n",
    "        lstm_output, (h,c) = self.lstm(sequence_output) ## extract the 1st token's embeddings\n",
    "        hidden = torch.cat((lstm_output[:,-1, :256],lstm_output[:,0, 256:]),dim=-1)\n",
    "        linear_output = self.linear(hidden.view(-1,256*2))\n",
    "        \n",
    "        self.logits = linear_output\n",
    "        return self.softmax(linear_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model class and tokenizer\n",
    "config = MyConfig(4)\n",
    "model = BERT_Bi_Arch(config)\n",
    "model.load_state_dict(torch.load(\"./stored_weights/polarityBertBiLSTM.pth\")) # load weights\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\") # load tokenizer\n",
    "model_wrapper = HuggingFaceModelWrapper(model, tokenizer) # wrap model and tokenizer together, textattack module needs this\n",
    "model_wrapper.model.config.max_position_embeddings = 150\n",
    "\n",
    "dataset = textattack.datasets.Dataset(temp_text_truncated)\n",
    "\n",
    "# Attack 2500 samples with CSV logging and checkpointing  every 250 intervals \n",
    "attack = textattack.attack_recipes.A2TYoo2021.build(model_wrapper, mlm=True) # A2TYoo2021\n",
    "attack_args = textattack.AttackArgs(query_budget = 100, num_examples=len(dataset), log_to_csv=\"A2TYoo2021.csv\", checkpoint_interval=250, checkpoint_dir=\"checkpoints\", disable_stdout=True)\n",
    "attacker = textattack.Attacker(attack, dataset, attack_args)\n",
    "attacker.attack_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of Successful Adversarial Attack: 51.96%\n",
      "Percentage of Failed Adversarial Attack: 38.56%\n",
      "Percentage of Skipped Adversarial Attack: 9.48%\n"
     ]
    }
   ],
   "source": [
    "# print adversarial examples metrics\n",
    "df = pd.read_csv(\"A2TYoo2021.csv\")\n",
    "\n",
    "succesful_attacks = df['result_type'].value_counts()['Successful'] / len(df) * 100\n",
    "print(f\"Percentage of Successful Adversarial Attack: {round(succesful_attacks,2)}%\")\n",
    "\n",
    "failed_attacks = df['result_type'].value_counts()['Failed'] / len(df) * 100\n",
    "print(f\"Percentage of Failed Adversarial Attack: {round(failed_attacks,2)}%\")\n",
    "\n",
    "skipped_attacks = df['result_type'].value_counts()['Skipped'] / len(df) * 100\n",
    "print(f\"Percentage of Skipped Adversarial Attack: {round(skipped_attacks,2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CZ4042_NN_Proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
